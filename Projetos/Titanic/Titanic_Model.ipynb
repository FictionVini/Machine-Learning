{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. train \n",
    "2. test\n",
    "3. Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Split arrays or matrices into random train and test subsets\n",
      "\n",
      "Quick utility that wraps input validation and\n",
      "``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "into a single call for splitting (and optionally subsampling) data in a\n",
      "oneliner.\n",
      "\n",
      "Read more in the :ref:`User Guide <cross_validation>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "*arrays : sequence of indexables with same length / shape[0]\n",
      "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "    matrices or pandas dataframes.\n",
      "\n",
      "test_size : float or int, default=None\n",
      "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "    of the dataset to include in the test split. If int, represents the\n",
      "    absolute number of test samples. If None, the value is set to the\n",
      "    complement of the train size. If ``train_size`` is also None, it will\n",
      "    be set to 0.25.\n",
      "\n",
      "train_size : float or int, default=None\n",
      "    If float, should be between 0.0 and 1.0 and represent the\n",
      "    proportion of the dataset to include in the train split. If\n",
      "    int, represents the absolute number of train samples. If None,\n",
      "    the value is automatically set to the complement of the test size.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Controls the shuffling applied to the data before applying the split.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "    then stratify must be None.\n",
      "\n",
      "stratify : array-like, default=None\n",
      "    If not None, data is split in a stratified fashion, using this as\n",
      "    the class labels.\n",
      "    Read more in the :ref:`User Guide <stratification>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "splitting : list, length=2 * len(arrays)\n",
      "    List containing train-test split of inputs.\n",
      "\n",
      "    .. versionadded:: 0.16\n",
      "        If the input is sparse, the output will be a\n",
      "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "        input type.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.model_selection import train_test_split\n",
      ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      ">>> X\n",
      "array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5],\n",
      "       [6, 7],\n",
      "       [8, 9]])\n",
      ">>> list(y)\n",
      "[0, 1, 2, 3, 4]\n",
      "\n",
      ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "...     X, y, test_size=0.33, random_state=42)\n",
      "...\n",
      ">>> X_train\n",
      "array([[4, 5],\n",
      "       [0, 1],\n",
      "       [6, 7]])\n",
      ">>> y_train\n",
      "[2, 0, 3]\n",
      ">>> X_test\n",
      "array([[2, 3],\n",
      "       [8, 9]])\n",
      ">>> y_test\n",
      "[1, 4]\n",
      "\n",
      ">>> train_test_split(y, shuffle=False)\n",
      "[[0, 1, 2], [3, 4]]\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\vinicius.garcia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Vini/Machine Learning/Machine-Learning/Projetos/Titanic/data/train.csv')\n",
    "df_test = pd.read_csv('C:/Vini/Machine Learning/Machine-Learning/Projetos/Titanic/data/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "Survived\n",
      "Pclass\n",
      "Name\n",
      "Sex\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Ticket\n",
      "Fare\n",
      "Cabin\n",
      "Embarked\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns.tolist():\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId missing values: 0\n",
      "Survived missing values: 0\n",
      "Pclass missing values: 0\n",
      "Name missing values: 0\n",
      "Sex missing values: 0\n",
      "Age missing values: 177\n",
      "SibSp missing values: 0\n",
      "Parch missing values: 0\n",
      "Ticket missing values: 0\n",
      "Fare missing values: 0\n",
      "Cabin missing values: 687\n",
      "Embarked missing values: 2\n"
     ]
    }
   ],
   "source": [
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():   \n",
    "        missing = df[col].isnull().sum()       \n",
    "        print(f'{col} missing values: {missing}')\n",
    "\n",
    "\n",
    "display_missing(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature targe count\n",
    "train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived  Sex   \n",
       "0         male      468\n",
       "1         female    233\n",
       "          male      109\n",
       "0         female     81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Survived', 'Sex']].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paula Mendes 'paula.mendes@americanas.io', Luis Varela 'luis.varela@lasa.com.br', Luis Varela 'luis.varela@americanas.io', Guilherme Brandao 'guilherme.brandao@lasa.com.br', Guilherme Brandao 'gbrandao@americanas.io', Rodrigo Cardoso 'rodrigo.cardoso@lasa.com.br', Rose Costa 'rose.costa@americanas.io', Rose Costa 'rose.costa@lasa.com.br', Rodrigo Cardoso 'rodrigo.cardoso@americanas.io', Vicente Sereno 'vicente.sereno@lasa.com.br', Vicente Sereno 'vicente.sereno@americanas.io', Lais Teixeira Araujo 'lais.teixeira@b2wdigital.com', Lais Teixeira Araujo 'lais.teixeira@americanas.io', lucas.tfreitas@b2wdigital.com, Lucas Tocantins Freitas 'lucas.tfreitas@americanas.io', Mariana Nogueirol 'mariana.nogueirol@lasa.com.br', Mariana Nogueirol 'mnogueirol@americanas.io', Rodolfo Moreira 'rodolfo.moreira@lasa.com.br', Rodolfo Moreira 'rrmoreira@americanas.io', Dilson Kaneco 'dilson.kaneco@lasa.com.br', Dilson Kaneco 'dilson.kaneco@americanas.io', Delermando Filho 'delermando.filho@lasa.com.br', Delermando Branquinho Filho 'delermando.filho@americanas.io', delermando.filho@b2wdigital.com, Coordenadores Abastecimento 'coordenadores-abastecimento@lasa.com.br', Matheus Braga 'matheus.braga@lasa.com.br', Viviane Santos 'viviane.santos@americanas.io', Evelyn Cristine Quintela de Oliveira Gaspar 'evelyn.gaspar@americanas.io', Ana Paula Pinho Macedo 'ana.pinho@americanas.io', Fernanda Paz 'fernanda.paz@americanas.io', Layz Souza 'lfeitoza@americanas.io', Bernardo Barbosa 'bernardo.barbosa@americanas.io', William Salvi 'william.salvi@americanas.io', planejamentovestuario 'planejamentovestuario@lasa.com.br', Tainara Rodrigues 'tainara.rodrigues@americanas.io', Thiago Andrade 'thiago.juvencio@americanas.io', Victória Nascimento 'vanascimento@americanas.io', Assistentes HBA 'Assistentes.HBA@lasa.com.br', Mariana Souza 'mariana.souza@lasa.com.br', Patricia Cavalcanti 'pcavalcanti@americanas.io', Andre Meneguite 'andre.meneguite@lasa.com.br', Ana Luíza Lima 'ana.lima@lasa.com.br', Dayvid Macieira 'dayvid.macieira@americanas.io', Viviane Barbosa Gusmao Winck 'viviane.winck@americanas.io', Alan de Andrade Aleluia 'alan.aleluia@americanas.io', Karla Cristina do Nascimento Pizza Matos 'karla.pizza@americanas.io', Paula Ventura Monteiro 'paula.monteiro@americanas.io', Andre Vasconcellos 'andre.vasconcellos@lasa.com.br', Tiago Chagas 'tiago.chagas@lasa.com.br', Margaret Barbosa 'margaret.barbosa@americanas.io', Jessica Ribeiro 'jessica.ribeiro@americanas.io', Ruan Sousa 'rschlenz@americanas.io', Filipe Soares da Silva 'filipe.soares@americanas.io', Deborah Garrido 'deborah.max@americanas.io', Westerley Chaves 'westerley.chaves@americanas.io', Assistentes Bomboniere 'assistentes.bomboniere@lasa.com.br', Victor Noppeney 'vnoppeney@americanas.io', Maira Roque 'maira.roque@americanas.io', Barbara Corazin 'barbara.corazin@lasa.com.br', Paulo Orgam 'paulo.orgam@americanas.io', Mauricio Curty 'mauricio.curty@americanas.io', Rafael Sampaio 'rafael.sampaio@americanas.io', Matheus Souza 'matheus.martins@lasa.com.br', Fernanda Pedrosa 'fapedrosa@americanas.io', Fernanda Pedrosa 'fernanda.pedrosa@lasa.com.br', Paulo Vinicius 'pasilva@americanas.io', Gabriel Novo 'gabriel.novo@americanas.io', Julia Silva 'jbgarcia@americanas.io', Mauro Santos 'mamagalhaes@americanas.io', Decio Filho, Higor Vieira 'hfvieira@americanas.io', Juliana Lassance 'jlassance@americanas.io', Abastecimento Lojas Novas 'abastecimento.lojas.novas@lasa.com.br', Abastecimento Brinquedos 'abastecimento_brinquedos@lasa.com.br', Mateus Costa 'mateus.costa@americanas.io', Tiago Machado 'tiago.machado@americanas.io', Rayssa Ferrari 'rayssa.ferrari@americanas.io', Anna Pinto 'anna.pinto@lasa.com.br', Bernard Silveira 'bernard.silveira@americanas.io', Priscila Nobile 'priscila.nobile@b2wdigital.com', Priscila Nobile 'priscila.nobile@americanas.io', Jessica de Souza de Melo 'jessica.sdmelo@b2wdigital.com', Jessica de Souza de Melo 'jessica.sdmelo@americanas.io', Larissa Meirelles Dantas 'larissa.dantas@b2wdigital.com', Rebeca Silva Reis 'rebeca.sreis@b2wdigital.com', Rebeca Silva Reis 'rebeca.sreis@americanas.io', Beatriz Maciel Abdon Oliveira 'beatriz.abdon@b2wdigital.com', Beatriz Maciel Abdon Oliveira 'beatriz.abdon@americanas.io', Juliana Sant Anna 'janna@americanas.io', Joao Vitor dos Santos Calixto 'joao.calixto@americanas.io', Abastecimento Lojas Novas 'abastecimento.lojas.novas@americanas.io', Bernardo Beja 'bernardo.beja@americanas.io', Henrique Augusto Maravelli 'henrique.maravelli@americanas.io', Bruno Duarte Teixeira 'bruno.dteixeira@americanas.io', Ramon Reis Venancio da Silva 'ramon.venancio@americanas.io', Nathalia Aparecida Trabulsi Ribeiro 'nathalia.trabulsi@americanas.io', Nicolly Fagundes Carvalho 'nicolly.carvalho@americanas.io', Luis Andre Natus Junior 'luis.natus@americanas.io', Lucca Peres Cesar 'lucca.cesar@americanas.io', Bianca Reis de Souza Menegazzo 'bianca.menegazzo@americanas.io', Bruno Villela 'bruno.villela@americanas.io', Joao Pedro Alves Cordeiro dos Santos 'joao.acsantos@americanas.io', Joao Vitor de Souza 'joao.vdsouza@americanas.io'\n"
     ]
    }
   ],
   "source": [
    "a = 'Paula Mendes <paula.mendes@americanas.io>; Luis Varela <luis.varela@lasa.com.br>; Luis Varela <luis.varela@americanas.io>; Guilherme Brandao <guilherme.brandao@lasa.com.br>; Guilherme Brandao <gbrandao@americanas.io>; Rodrigo Cardoso <rodrigo.cardoso@lasa.com.br>; Rose Costa <rose.costa@americanas.io>; Rose Costa <rose.costa@lasa.com.br>; Rodrigo Cardoso <rodrigo.cardoso@americanas.io>; Vicente Sereno <vicente.sereno@lasa.com.br>; Vicente Sereno <vicente.sereno@americanas.io>; Lais Teixeira Araujo <lais.teixeira@b2wdigital.com>; Lais Teixeira Araujo <lais.teixeira@americanas.io>; lucas.tfreitas@b2wdigital.com; Lucas Tocantins Freitas <lucas.tfreitas@americanas.io>; Mariana Nogueirol <mariana.nogueirol@lasa.com.br>; Mariana Nogueirol <mnogueirol@americanas.io>; Rodolfo Moreira <rodolfo.moreira@lasa.com.br>; Rodolfo Moreira <rrmoreira@americanas.io>; Dilson Kaneco <dilson.kaneco@lasa.com.br>; Dilson Kaneco <dilson.kaneco@americanas.io>; Delermando Filho <delermando.filho@lasa.com.br>; Delermando Branquinho Filho <delermando.filho@americanas.io>; delermando.filho@b2wdigital.com; Coordenadores Abastecimento <coordenadores-abastecimento@lasa.com.br>; Matheus Braga <matheus.braga@lasa.com.br>; Viviane Santos <viviane.santos@americanas.io>; Evelyn Cristine Quintela de Oliveira Gaspar <evelyn.gaspar@americanas.io>; Ana Paula Pinho Macedo <ana.pinho@americanas.io>; Fernanda Paz <fernanda.paz@americanas.io>; Layz Souza <lfeitoza@americanas.io>; Bernardo Barbosa <bernardo.barbosa@americanas.io>; William Salvi <william.salvi@americanas.io>; planejamentovestuario <planejamentovestuario@lasa.com.br>; Tainara Rodrigues <tainara.rodrigues@americanas.io>; Thiago Andrade <thiago.juvencio@americanas.io>; Victória Nascimento <vanascimento@americanas.io>; Assistentes HBA <Assistentes.HBA@lasa.com.br>; Mariana Souza <mariana.souza@lasa.com.br>; Patricia Cavalcanti <pcavalcanti@americanas.io>; Andre Meneguite <andre.meneguite@lasa.com.br>; Ana Luíza Lima <ana.lima@lasa.com.br>; Dayvid Macieira <dayvid.macieira@americanas.io>; Viviane Barbosa Gusmao Winck <viviane.winck@americanas.io>; Alan de Andrade Aleluia <alan.aleluia@americanas.io>; Karla Cristina do Nascimento Pizza Matos <karla.pizza@americanas.io>; Paula Ventura Monteiro <paula.monteiro@americanas.io>; Andre Vasconcellos <andre.vasconcellos@lasa.com.br>; Tiago Chagas <tiago.chagas@lasa.com.br>; Margaret Barbosa <margaret.barbosa@americanas.io>; Jessica Ribeiro <jessica.ribeiro@americanas.io>; Ruan Sousa <rschlenz@americanas.io>; Filipe Soares da Silva <filipe.soares@americanas.io>; Deborah Garrido <deborah.max@americanas.io>; Westerley Chaves <westerley.chaves@americanas.io>; Assistentes Bomboniere <assistentes.bomboniere@lasa.com.br>; Victor Noppeney <vnoppeney@americanas.io>; Maira Roque <maira.roque@americanas.io>; Barbara Corazin <barbara.corazin@lasa.com.br>; Paulo Orgam <paulo.orgam@americanas.io>; Mauricio Curty <mauricio.curty@americanas.io>; Rafael Sampaio <rafael.sampaio@americanas.io>; Matheus Souza <matheus.martins@lasa.com.br>; Fernanda Pedrosa <fapedrosa@americanas.io>; Fernanda Pedrosa <fernanda.pedrosa@lasa.com.br>; Paulo Vinicius <pasilva@americanas.io>; Gabriel Novo <gabriel.novo@americanas.io>; Julia Silva <jbgarcia@americanas.io>; Mauro Santos <mamagalhaes@americanas.io>; Decio Filho; Higor Vieira <hfvieira@americanas.io>; Juliana Lassance <jlassance@americanas.io>; Abastecimento Lojas Novas <abastecimento.lojas.novas@lasa.com.br>; Abastecimento Brinquedos <abastecimento_brinquedos@lasa.com.br>; Mateus Costa <mateus.costa@americanas.io>; Tiago Machado <tiago.machado@americanas.io>; Rayssa Ferrari <rayssa.ferrari@americanas.io>; Anna Pinto <anna.pinto@lasa.com.br>; Bernard Silveira <bernard.silveira@americanas.io>; Priscila Nobile <priscila.nobile@b2wdigital.com>; Priscila Nobile <priscila.nobile@americanas.io>; Jessica de Souza de Melo <jessica.sdmelo@b2wdigital.com>; Jessica de Souza de Melo <jessica.sdmelo@americanas.io>; Larissa Meirelles Dantas <larissa.dantas@b2wdigital.com>; Rebeca Silva Reis <rebeca.sreis@b2wdigital.com>; Rebeca Silva Reis <rebeca.sreis@americanas.io>; Beatriz Maciel Abdon Oliveira <beatriz.abdon@b2wdigital.com>; Beatriz Maciel Abdon Oliveira <beatriz.abdon@americanas.io>; Juliana Sant Anna <janna@americanas.io>; Joao Vitor dos Santos Calixto <joao.calixto@americanas.io>; Abastecimento Lojas Novas <abastecimento.lojas.novas@americanas.io>; Bernardo Beja <bernardo.beja@americanas.io>; Henrique Augusto Maravelli <henrique.maravelli@americanas.io>; Bruno Duarte Teixeira <bruno.dteixeira@americanas.io>; Ramon Reis Venancio da Silva <ramon.venancio@americanas.io>; Nathalia Aparecida Trabulsi Ribeiro <nathalia.trabulsi@americanas.io>; Nicolly Fagundes Carvalho <nicolly.carvalho@americanas.io>; Luis Andre Natus Junior <luis.natus@americanas.io>; Lucca Peres Cesar <lucca.cesar@americanas.io>; Bianca Reis de Souza Menegazzo <bianca.menegazzo@americanas.io>; Bruno Villela <bruno.villela@americanas.io>; Joao Pedro Alves Cordeiro dos Santos <joao.acsantos@americanas.io>; Joao Vitor de Souza <joao.vdsouza@americanas.io>'\n",
    "this = a.replace(';', ',')\n",
    "this = this.replace('>', \"'\")\n",
    "this = this.replace('<', \"'\")\n",
    "print(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Paula Mendes 'paula.mendes@americanas.io', Luis Varela 'luis.varela@lasa.com.br', Luis Varela 'luis.varela@americanas.io', Guilherme Brandao 'guilherme.brandao@lasa.com.br', Guilherme Brandao 'gbrandao@americanas.io', Rodrigo Cardoso 'rodrigo.cardoso@lasa.com.br', Rose Costa 'rose.costa@americanas.io', Rose Costa 'rose.costa@lasa.com.br', Rodrigo Cardoso 'rodrigo.cardoso@americanas.io', Vicente Sereno 'vicente.sereno@lasa.com.br', Vicente Sereno 'vicente.sereno@americanas.io', Lais Teixeira Araujo 'lais.teixeira@b2wdigital.com', Lais Teixeira Araujo 'lais.teixeira@americanas.io', lucas.tfreitas@b2wdigital.com, Lucas Tocantins Freitas 'lucas.tfreitas@americanas.io', Mariana Nogueirol 'mariana.nogueirol@lasa.com.br', Mariana Nogueirol 'mnogueirol@americanas.io', Rodolfo Moreira 'rodolfo.moreira@lasa.com.br', Rodolfo Moreira 'rrmoreira@americanas.io', Dilson Kaneco 'dilson.kaneco@lasa.com.br', Dilson Kaneco 'dilson.kaneco@americanas.io', Delermando Filho 'delermando.filho@lasa.com.br', Delermando Branquinho Filho 'delermando.filho@americanas.io', delermando.filho@b2wdigital.com, Coordenadores Abastecimento 'coordenadores-abastecimento@lasa.com.br', Matheus Braga 'matheus.braga@lasa.com.br', Viviane Santos 'viviane.santos@americanas.io', Evelyn Cristine Quintela de Oliveira Gaspar 'evelyn.gaspar@americanas.io', Ana Paula Pinho Macedo 'ana.pinho@americanas.io', Fernanda Paz 'fernanda.paz@americanas.io', Layz Souza 'lfeitoza@americanas.io', Bernardo Barbosa 'bernardo.barbosa@americanas.io', William Salvi 'william.salvi@americanas.io', planejamentovestuario 'planejamentovestuario@lasa.com.br', Tainara Rodrigues 'tainara.rodrigues@americanas.io', Thiago Andrade 'thiago.juvencio@americanas.io', Victória Nascimento 'vanascimento@americanas.io', Assistentes HBA 'Assistentes.HBA@lasa.com.br', Mariana Souza 'mariana.souza@lasa.com.br', Patricia Cavalcanti 'pcavalcanti@americanas.io', Andre Meneguite 'andre.meneguite@lasa.com.br', Ana Luíza Lima 'ana.lima@lasa.com.br', Dayvid Macieira 'dayvid.macieira@americanas.io', Viviane Barbosa Gusmao Winck 'viviane.winck@americanas.io', Alan de Andrade Aleluia 'alan.aleluia@americanas.io', Karla Cristina do Nascimento Pizza Matos 'karla.pizza@americanas.io', Paula Ventura Monteiro 'paula.monteiro@americanas.io', Andre Vasconcellos 'andre.vasconcellos@lasa.com.br', Tiago Chagas 'tiago.chagas@lasa.com.br', Margaret Barbosa 'margaret.barbosa@americanas.io', Jessica Ribeiro 'jessica.ribeiro@americanas.io', Ruan Sousa 'rschlenz@americanas.io', Filipe Soares da Silva 'filipe.soares@americanas.io', Deborah Garrido 'deborah.max@americanas.io', Westerley Chaves 'westerley.chaves@americanas.io', Assistentes Bomboniere 'assistentes.bomboniere@lasa.com.br', Victor Noppeney 'vnoppeney@americanas.io', Maira Roque 'maira.roque@americanas.io', Barbara Corazin 'barbara.corazin@lasa.com.br', Paulo Orgam 'paulo.orgam@americanas.io', Mauricio Curty 'mauricio.curty@americanas.io', Rafael Sampaio 'rafael.sampaio@americanas.io', Matheus Souza 'matheus.martins@lasa.com.br', Fernanda Pedrosa 'fapedrosa@americanas.io', Fernanda Pedrosa 'fernanda.pedrosa@lasa.com.br', Paulo Vinicius 'pasilva@americanas.io', Gabriel Novo 'gabriel.novo@americanas.io', Julia Silva 'jbgarcia@americanas.io', Mauro Santos 'mamagalhaes@americanas.io', Decio Filho, Higor Vieira 'hfvieira@americanas.io', Juliana Lassance 'jlassance@americanas.io', Abastecimento Lojas Novas 'abastecimento.lojas.novas@lasa.com.br', Abastecimento Brinquedos 'abastecimento_brinquedos@lasa.com.br', Mateus Costa 'mateus.costa@americanas.io', Tiago Machado 'tiago.machado@americanas.io', Rayssa Ferrari 'rayssa.ferrari@americanas.io', Anna Pinto 'anna.pinto@lasa.com.br', Bernard Silveira 'bernard.silveira@americanas.io', Priscila Nobile 'priscila.nobile@b2wdigital.com', Priscila Nobile 'priscila.nobile@americanas.io', Jessica de Souza de Melo 'jessica.sdmelo@b2wdigital.com', Jessica de Souza de Melo 'jessica.sdmelo@americanas.io', Larissa Meirelles Dantas 'larissa.dantas@b2wdigital.com', Rebeca Silva Reis 'rebeca.sreis@b2wdigital.com', Rebeca Silva Reis 'rebeca.sreis@americanas.io', Beatriz Maciel Abdon Oliveira 'beatriz.abdon@b2wdigital.com', Beatriz Maciel Abdon Oliveira 'beatriz.abdon@americanas.io', Juliana Sant Anna 'janna@americanas.io', Joao Vitor dos Santos Calixto 'joao.calixto@americanas.io', Abastecimento Lojas Novas 'abastecimento.lojas.novas@americanas.io', Bernardo Beja 'bernardo.beja@americanas.io', Henrique Augusto Maravelli 'henrique.maravelli@americanas.io', Bruno Duarte Teixeira 'bruno.dteixeira@americanas.io', Ramon Reis Venancio da Silva 'ramon.venancio@americanas.io', Nathalia Aparecida Trabulsi Ribeiro 'nathalia.trabulsi@americanas.io', Nicolly Fagundes Carvalho 'nicolly.carvalho@americanas.io', Luis Andre Natus Junior 'luis.natus@americanas.io', Lucca Peres Cesar 'lucca.cesar@americanas.io', Bianca Reis de Souza Menegazzo 'bianca.menegazzo@americanas.io', Bruno Villela 'bruno.villela@americanas.io', Joao Pedro Alves Cordeiro dos Santos 'joao.acsantos@americanas.io', Joao Vitor de Souza 'joao.vdsouza@americanas.io'\n"
     ]
    }
   ],
   "source": [
    "for cont, i in enumerate(lista):\n",
    "    print(cont, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic pre processing data\n",
    "def transform_sex(_column):\n",
    "    if _column == 'female':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train['sex'] = train['Sex'].map(transform_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['sex', 'Age']]\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "for i in range(x):\n",
    "    x -= 2\n",
    "    print(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Vini\\Machine Learning\\Machine-Learning\\Projetos\\Titanic\\Titanic_Model.ipynb Célula: 7\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Vini/Machine%20Learning/Machine-Learning/Projetos/Titanic/Titanic_Model.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Vini/Machine%20Learning/Machine-Learning/Projetos/Titanic/Titanic_Model.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Vini/Machine%20Learning/Machine-Learning/Projetos/Titanic/Titanic_Model.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX_train, y \u001b[39m=\u001b[39;49m y_train)\n",
      "File \u001b[1;32mc:\\Users\\vinicius.garcia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:326\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    325\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 326\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    327\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    328\u001b[0m )\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\vinicius.garcia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:572\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    571\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 572\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    573\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\vinicius.garcia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:956\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 956\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    957\u001b[0m     X,\n\u001b[0;32m    958\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    959\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    961\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    962\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    963\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    964\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    965\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    966\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    967\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    968\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    969\u001b[0m )\n\u001b[0;32m    971\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    973\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\vinicius.garcia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:792\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    787\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    788\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    791\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 792\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    794\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    795\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\vinicius.garcia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misinf(X)\u001b[39m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(X)\u001b[39m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minfinity\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m allow_nan \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNaN, infinity\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[39mif\u001b[39;00m msg_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=1, random_state=0)\n",
    "model.fit(X=X_train, y = y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc16c55873c5a6e73f339e297ef0fafd4d0351f9c3a39adeaa4dfbd60a3966e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
